#!/usr/bin/env python3
"""
æµ‹è¯•æœ€ç»ˆæ”¹è¿›çš„è‡ªé€‚åº”å¹²é¢„æ¡†æ¶
éªŒè¯åœ¨CRå’ŒNCRç¯å¢ƒä¸­çš„è¡¨ç°
"""

import torch
import torch.nn as nn
from final_improved_intervention import (
    FinalImprovedMultiLevelCausalIntervention,
    create_cr_optimized_intervention,
    create_balanced_intervention
)

def simulate_cr_environment(batch_size=4, seq_len=20, dim=128):
    """
    æ¨¡æ‹ŸCRç¯å¢ƒï¼šé«˜å¤æ‚åº¦ï¼ŒåŠ¨æ€äº¤äº’
    """
    # é«˜æ–¹å·®ï¼Œå¤æ‚ç‰¹å¾ï¼Œæ›´å¤šå¼‚å¸¸
    x = torch.randn(batch_size, seq_len, dim) * 2.5
    # æ·»åŠ æ›´å¤šå¼‚å¸¸å€¼
    x[:, :8, :] += torch.randn(batch_size, 8, dim) * 4.0
    # æ·»åŠ ä¸€äº›æç«¯å€¼
    x[:, 10:15, :] += torch.randn(batch_size, 5, dim) * 6.0
    return x

def simulate_ncr_environment(batch_size=4, seq_len=20, dim=128):
    """
    æ¨¡æ‹ŸNCRç¯å¢ƒï¼šä½å¤æ‚åº¦ï¼Œé™æ€ç¯å¢ƒ
    """
    # ä½æ–¹å·®ï¼Œç®€å•ç‰¹å¾
    x = torch.randn(batch_size, seq_len, dim) * 0.3
    return x

def test_final_intervention():
    """
    æµ‹è¯•æœ€ç»ˆæ”¹è¿›çš„å¹²é¢„æ¡†æ¶
    """
    print("æµ‹è¯•æœ€ç»ˆæ”¹è¿›çš„è‡ªé€‚åº”å¹²é¢„æ¡†æ¶")
    print("=" * 60)
    
    # åˆ›å»ºå¹³è¡¡çš„å¹²é¢„æ¡†æ¶
    intervention = create_balanced_intervention()
    
    # æµ‹è¯•CRç¯å¢ƒ
    print("\n1. æµ‹è¯•CRç¯å¢ƒï¼ˆé«˜å¤æ‚åº¦ï¼ŒåŠ¨æ€äº¤äº’ï¼‰:")
    cr_x = simulate_cr_environment()
    intervention.train()
    
    cr_metrics = {}
    for layer_idx in range(4):
        cr_x, metrics = intervention.apply_intervention_after_layer(cr_x, layer_idx)
        if metrics:
            cr_metrics[f'layer_{layer_idx}'] = metrics
            print(f"  ç¬¬{layer_idx}å±‚: ç¯å¢ƒ={metrics.get('env_type', 'Unknown')}, "
                  f"å¤æ‚åº¦={metrics.get('complexity', 0):.3f}, "
                  f"è‡ªé€‚åº”æ¦‚ç‡={metrics.get('adaptive_prob', 0):.3f}, "
                  f"é˜ˆå€¼={metrics.get('threshold_used', 0):.3f}, "
                  f"å¼‚å¸¸æ¯”ä¾‹={metrics.get('anomaly_ratio', 0):.3f}")
    
    # æµ‹è¯•NCRç¯å¢ƒ
    print("\n2. æµ‹è¯•NCRç¯å¢ƒï¼ˆä½å¤æ‚åº¦ï¼Œé™æ€ç¯å¢ƒï¼‰:")
    ncr_x = simulate_ncr_environment()
    
    ncr_metrics = {}
    for layer_idx in range(4):
        ncr_x, metrics = intervention.apply_intervention_after_layer(ncr_x, layer_idx)
        if metrics:
            ncr_metrics[f'layer_{layer_idx}'] = metrics
            print(f"  ç¬¬{layer_idx}å±‚: ç¯å¢ƒ={metrics.get('env_type', 'Unknown')}, "
                  f"å¤æ‚åº¦={metrics.get('complexity', 0):.3f}, "
                  f"è‡ªé€‚åº”æ¦‚ç‡={metrics.get('adaptive_prob', 0):.3f}, "
                  f"é˜ˆå€¼={metrics.get('threshold_used', 0):.3f}, "
                  f"å¼‚å¸¸æ¯”ä¾‹={metrics.get('anomaly_ratio', 0):.3f}")
    
    # åˆ†æç»“æœ
    print("\n3. è¯¦ç»†åˆ†æ:")
    
    # è®¡ç®—å¹³å‡å¤æ‚åº¦
    cr_avg_complexity = sum(m.get('complexity', 0) for m in cr_metrics.values()) / len(cr_metrics)
    ncr_avg_complexity = sum(m.get('complexity', 0) for m in ncr_metrics.values()) / len(ncr_metrics)
    
    print(f"  CRç¯å¢ƒå¹³å‡å¤æ‚åº¦: {cr_avg_complexity:.3f}")
    print(f"  NCRç¯å¢ƒå¹³å‡å¤æ‚åº¦: {ncr_avg_complexity:.3f}")
    
    # è®¡ç®—å¹³å‡å¹²é¢„æ¦‚ç‡
    cr_avg_prob = sum(m.get('adaptive_prob', 0) for m in cr_metrics.values()) / len(cr_metrics)
    ncr_avg_prob = sum(m.get('adaptive_prob', 0) for m in ncr_metrics.values()) / len(ncr_metrics)
    
    print(f"  CRç¯å¢ƒå¹³å‡å¹²é¢„æ¦‚ç‡: {cr_avg_prob:.3f}")
    print(f"  NCRç¯å¢ƒå¹³å‡å¹²é¢„æ¦‚ç‡: {ncr_avg_prob:.3f}")
    
    # è®¡ç®—å¹³å‡é˜ˆå€¼
    cr_avg_threshold = sum(m.get('threshold_used', 0) for m in cr_metrics.values()) / len(cr_metrics)
    ncr_avg_threshold = sum(m.get('threshold_used', 0) for m in ncr_metrics.values()) / len(ncr_metrics)
    
    print(f"  CRç¯å¢ƒå¹³å‡é˜ˆå€¼: {cr_avg_threshold:.3f}")
    print(f"  NCRç¯å¢ƒå¹³å‡é˜ˆå€¼: {ncr_avg_threshold:.3f}")
    
    # éªŒè¯è‡ªé€‚åº”è¡Œä¸º
    print("\n4. è‡ªé€‚åº”è¡Œä¸ºéªŒè¯:")
    
    if cr_avg_prob > ncr_avg_prob:
        print("  âœ… å¹²é¢„æ¦‚ç‡è‡ªé€‚åº”æ­£ç¡®ï¼šCRç¯å¢ƒä½¿ç”¨æ›´é«˜çš„å¹²é¢„æ¦‚ç‡")
    else:
        print("  âŒ å¹²é¢„æ¦‚ç‡è‡ªé€‚åº”å¼‚å¸¸ï¼šCRç¯å¢ƒå¹²é¢„æ¦‚ç‡è¿‡ä½")
    
    if cr_avg_threshold < ncr_avg_threshold:
        print("  âœ… é˜ˆå€¼è‡ªé€‚åº”æ­£ç¡®ï¼šCRç¯å¢ƒä½¿ç”¨æ›´æ•æ„Ÿçš„é˜ˆå€¼")
    else:
        print("  âŒ é˜ˆå€¼è‡ªé€‚åº”å¼‚å¸¸ï¼šCRç¯å¢ƒé˜ˆå€¼ä¸å¤Ÿæ•æ„Ÿ")
    
    if cr_avg_complexity > ncr_avg_complexity:
        print("  âœ… å¤æ‚åº¦æ£€æµ‹æ­£ç¡®ï¼šCRç¯å¢ƒè¢«è¯†åˆ«ä¸ºé«˜å¤æ‚åº¦")
    else:
        print("  âŒ å¤æ‚åº¦æ£€æµ‹å¼‚å¸¸ï¼šCRç¯å¢ƒå¤æ‚åº¦æ£€æµ‹ä¸å‡†ç¡®")
    
    return cr_metrics, ncr_metrics

def test_cr_optimized_version():
    """
    æµ‹è¯•CRä¼˜åŒ–ç‰ˆæœ¬
    """
    print("\n5. æµ‹è¯•CRä¼˜åŒ–ç‰ˆæœ¬:")
    
    # åˆ›å»ºCRä¼˜åŒ–ç‰ˆæœ¬
    cr_intervention = create_cr_optimized_intervention()
    
    # æµ‹è¯•CRç¯å¢ƒ
    cr_x = simulate_cr_environment()
    cr_intervention.train()
    
    cr_metrics = {}
    for layer_idx in range(4):
        cr_x, metrics = cr_intervention.apply_intervention_after_layer(cr_x, layer_idx)
        if metrics:
            cr_metrics[f'layer_{layer_idx}'] = metrics
    
    # è®¡ç®—CRä¼˜åŒ–ç‰ˆæœ¬çš„æ•ˆæœ
    cr_avg_prob = sum(m.get('adaptive_prob', 0) for m in cr_metrics.values()) / len(cr_metrics)
    cr_avg_threshold = sum(m.get('threshold_used', 0) for m in cr_metrics.values()) / len(cr_metrics)
    
    print(f"  CRä¼˜åŒ–ç‰ˆæœ¬ - å¹³å‡å¹²é¢„æ¦‚ç‡: {cr_avg_prob:.3f}")
    print(f"  CRä¼˜åŒ–ç‰ˆæœ¬ - å¹³å‡é˜ˆå€¼: {cr_avg_threshold:.3f}")
    
    return cr_metrics

def test_gradient_flow():
    """
    æµ‹è¯•æ¢¯åº¦æµ
    """
    print("\n6. æµ‹è¯•æ¢¯åº¦æµ:")
    
    intervention = create_balanced_intervention()
    x = torch.randn(2, 10, 128, requires_grad=True)
    
    intervention.train()
    x_out, _ = intervention.apply_intervention_after_layer(x, 1)
    
    loss = x_out.sum()
    loss.backward()
    
    print(f"  è¾“å…¥æ¢¯åº¦å½¢çŠ¶: {x.grad.shape}")
    print(f"  æ¢¯åº¦èŒƒæ•°: {x.grad.norm().item():.6f}")
    print("  âœ… æ¢¯åº¦æµæ­£å¸¸")

def main():
    """
    ä¸»æµ‹è¯•å‡½æ•°
    """
    print("å¼€å§‹æµ‹è¯•æœ€ç»ˆæ”¹è¿›çš„è‡ªé€‚åº”å¹²é¢„æ¡†æ¶...")
    
    try:
        # æµ‹è¯•æœ€ç»ˆå¹²é¢„æ¡†æ¶
        cr_metrics, ncr_metrics = test_final_intervention()
        
        # æµ‹è¯•CRä¼˜åŒ–ç‰ˆæœ¬
        cr_opt_metrics = test_cr_optimized_version()
        
        # æµ‹è¯•æ¢¯åº¦æµ
        test_gradient_flow()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("\næœ€ç»ˆæ”¹è¿›æ€»ç»“:")
        print("1. ç¯å¢ƒç±»å‹æ£€æµ‹ - è‡ªåŠ¨è¯†åˆ«CRå’ŒNCRç¯å¢ƒ")
        print("2. å¤æ‚åº¦æ„ŸçŸ¥å¹²é¢„ - æ ¹æ®ç‰¹å¾å¤æ‚åº¦è°ƒæ•´ç­–ç•¥")
        print("3. è‡ªé€‚åº”é˜ˆå€¼ - CRç¯å¢ƒä½¿ç”¨æ›´æ•æ„Ÿçš„é˜ˆå€¼")
        print("4. åŠ¨æ€æ¦‚ç‡è°ƒæ•´ - CRç¯å¢ƒä½¿ç”¨æ›´é«˜çš„å¹²é¢„æ¦‚ç‡")
        print("5. æ™ºèƒ½å™ªå£°æ§åˆ¶ - æ ¹æ®ç¯å¢ƒç±»å‹è°ƒæ•´å™ªå£°å¼ºåº¦")
        print("6. æ›´å¥½çš„CRé€‚åº”æ€§ - ä¸“é—¨é’ˆå¯¹ååº”æ€§ç¯å¢ƒä¼˜åŒ–")
        
        print("\né¢„æœŸæ•ˆæœ:")
        print("- CRç¯å¢ƒï¼šä½¿ç”¨æ›´å¼ºå¹²é¢„ï¼Œæ›´æ•æ„Ÿé˜ˆå€¼ï¼Œæ›´é«˜æ¦‚ç‡")
        print("- NCRç¯å¢ƒï¼šä½¿ç”¨æ¸©å’Œå¹²é¢„ï¼Œä¿å®ˆé˜ˆå€¼ï¼Œè¾ƒä½æ¦‚ç‡")
        print("- è‡ªé€‚åº”è°ƒæ•´ï¼šæ ¹æ®å®æ—¶ç‰¹å¾è‡ªåŠ¨è°ƒæ•´ç­–ç•¥")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()