#!/usr/bin/env python3
"""
æµ‹è¯•æ”¹è¿›çš„å› æœå¹²é¢„æ¡†æ¶çš„é›†æˆå’Œå…¼å®¹æ€§
"""

import torch
import torch.nn as nn
from improved_causal_intervention import (
    ConservativeAnomalyDetector,
    SmartFeatureDecorrelation,
    ImprovedCausalGate,
    FeatureProtection,
    GradualIntervention,
    ImprovedUltraLightLayerIntervention,
    MultiLevelCausalIntervention2_2,
    ConservativeIntervention,
    BalancedIntervention,
    AggressiveIntervention
)

def test_conservative_anomaly_detector():
    """æµ‹è¯•ä¿å®ˆå¼‚å¸¸æ£€æµ‹å™¨"""
    print("æµ‹è¯• ConservativeAnomalyDetector...")
    
    detector = ConservativeAnomalyDetector(dim=128)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len, dim = 2, 10, 128
    x = torch.randn(batch_size, seq_len, dim)
    key_padding_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)
    
    # è®­ç»ƒæ¨¡å¼æµ‹è¯•
    detector.train()
    x_out, metrics = detector(x, noise_scale=0.05, key_padding_mask=key_padding_mask)
    
    assert x_out.shape == x.shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {x_out.shape} vs {x.shape}"
    assert metrics is not None, "åº”è¯¥è¿”å›æŒ‡æ ‡"
    assert 'anomaly_ratio' in metrics, "åº”è¯¥åŒ…å«å¼‚å¸¸æ¯”ä¾‹æŒ‡æ ‡"
    
    print("âœ“ ConservativeAnomalyDetector æµ‹è¯•é€šè¿‡")
    return True

def test_smart_feature_decorrelation():
    """æµ‹è¯•æ™ºèƒ½ç‰¹å¾å»ç›¸å…³"""
    print("æµ‹è¯• SmartFeatureDecorrelation...")
    
    decorrelation = SmartFeatureDecorrelation(dim=128)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len, dim = 2, 10, 128
    x = torch.randn(batch_size, seq_len, dim)
    
    # è®­ç»ƒæ¨¡å¼æµ‹è¯•
    decorrelation.train()
    x_out = decorrelation(x)
    
    assert x_out.shape == x.shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {x_out.shape} vs {x.shape}"
    
    print("âœ“ SmartFeatureDecorrelation æµ‹è¯•é€šè¿‡")
    return True

def test_improved_causal_gate():
    """æµ‹è¯•æ”¹è¿›çš„å› æœé—¨æ§"""
    print("æµ‹è¯• ImprovedCausalGate...")
    
    gate = ImprovedCausalGate(dim=128)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len, dim = 2, 10, 128
    x = torch.randn(batch_size, seq_len, dim)
    key_padding_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)
    
    x_out = gate(x, key_padding_mask)
    
    assert x_out.shape == x.shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {x_out.shape} vs {x.shape}"
    
    print("âœ“ ImprovedCausalGate æµ‹è¯•é€šè¿‡")
    return True

def test_feature_protection():
    """æµ‹è¯•ç‰¹å¾ä¿æŠ¤"""
    print("æµ‹è¯• FeatureProtection...")
    
    protection = FeatureProtection(dim=128)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len, dim = 2, 10, 128
    x = torch.randn(batch_size, seq_len, dim)
    intervention_mask = torch.ones(batch_size, seq_len, 1)
    
    protected_mask = protection(x, intervention_mask)
    
    assert protected_mask.shape == intervention_mask.shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {protected_mask.shape} vs {intervention_mask.shape}"
    
    print("âœ“ FeatureProtection æµ‹è¯•é€šè¿‡")
    return True

def test_gradual_intervention():
    """æµ‹è¯•æ¸è¿›å¼å¹²é¢„"""
    print("æµ‹è¯• GradualIntervention...")
    
    intervention = GradualIntervention(dim=128)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len, dim = 2, 10, 128
    x = torch.randn(batch_size, seq_len, dim)
    anomaly_score = torch.rand(batch_size, seq_len)
    noise_scale = 0.1
    
    x_out = intervention(x, anomaly_score, noise_scale)
    
    assert x_out.shape == x.shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {x_out.shape} vs {x.shape}"
    
    print("âœ“ GradualIntervention æµ‹è¯•é€šè¿‡")
    return True

def test_improved_ultra_light_layer():
    """æµ‹è¯•æ”¹è¿›çš„è¶…è½»é‡çº§å±‚å¹²é¢„"""
    print("æµ‹è¯• ImprovedUltraLightLayerIntervention...")
    
    layer_intervention = ImprovedUltraLightLayerIntervention(
        dim=128,
        layer_idx=1,
        total_layers=4,
        base_intervention_prob=0.3
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len, dim = 2, 10, 128
    x = torch.randn(batch_size, seq_len, dim)
    key_padding_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)
    
    # è®­ç»ƒæ¨¡å¼æµ‹è¯•
    layer_intervention.train()
    x_out, metrics = layer_intervention(x, key_padding_mask)
    
    assert x_out.shape == x.shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {x_out.shape} vs {x.shape}"
    
    print("âœ“ ImprovedUltraLightLayerIntervention æµ‹è¯•é€šè¿‡")
    return True

def test_multi_level_intervention():
    """æµ‹è¯•å¤šå±‚çº§å¹²é¢„æ¡†æ¶"""
    print("æµ‹è¯• MultiLevelCausalIntervention2_2...")
    
    multi_intervention = MultiLevelCausalIntervention2_2(
        dim=128,
        encoder_depth=4,
        base_intervention_prob=0.25,
        base_noise_scale=0.08
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len, dim = 2, 10, 128
    x = torch.randn(batch_size, seq_len, dim)
    key_padding_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)
    
    # è®­ç»ƒæ¨¡å¼æµ‹è¯•
    multi_intervention.train()
    
    # æµ‹è¯•æ¯å±‚çš„å¹²é¢„
    for layer_idx in range(4):
        x_out, metrics = multi_intervention.apply_intervention_after_layer(
            x, layer_idx, key_padding_mask
        )
        assert x_out.shape == x.shape, f"ç¬¬{layer_idx}å±‚è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {x_out.shape} vs {x.shape}"
    
    # æµ‹è¯•è·å–æŒ‡æ ‡
    all_metrics = multi_intervention.get_all_metrics()
    assert isinstance(all_metrics, dict), "åº”è¯¥è¿”å›å­—å…¸ç±»å‹çš„æŒ‡æ ‡"
    
    print("âœ“ MultiLevelCausalIntervention2_2 æµ‹è¯•é€šè¿‡")
    return True

def test_intervention_strategies():
    """æµ‹è¯•ä¸åŒå¹²é¢„ç­–ç•¥"""
    print("æµ‹è¯•å¹²é¢„ç­–ç•¥...")
    
    dim = 128
    batch_size, seq_len = 2, 10
    x = torch.randn(batch_size, seq_len, dim)
    key_padding_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)
    
    # æµ‹è¯•ä¿å®ˆå¹²é¢„
    conservative = ConservativeIntervention(dim, prob=0.1)
    conservative.train()
    x_out, _ = conservative(x, key_padding_mask)
    assert x_out.shape == x.shape
    
    # æµ‹è¯•å¹³è¡¡å¹²é¢„
    balanced = BalancedIntervention(dim, prob=0.3)
    balanced.train()
    x_out, _ = balanced(x, key_padding_mask)
    assert x_out.shape == x.shape
    
    # æµ‹è¯•ç§¯æå¹²é¢„
    aggressive = AggressiveIntervention(dim, prob=0.5)
    aggressive.train()
    x_out, _ = aggressive(x, key_padding_mask)
    assert x_out.shape == x.shape
    
    print("âœ“ å¹²é¢„ç­–ç•¥æµ‹è¯•é€šè¿‡")
    return True

def test_gradient_flow():
    """æµ‹è¯•æ¢¯åº¦æµ"""
    print("æµ‹è¯•æ¢¯åº¦æµ...")
    
    multi_intervention = MultiLevelCausalIntervention2_2(
        dim=128,
        encoder_depth=4,
        base_intervention_prob=0.25,
        base_noise_scale=0.08
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len, dim = 2, 10, 128
    x = torch.randn(batch_size, seq_len, dim, requires_grad=True)
    key_padding_mask = torch.zeros(batch_size, seq_len, dtype=torch.bool)
    
    # è®­ç»ƒæ¨¡å¼
    multi_intervention.train()
    
    # å‰å‘ä¼ æ’­
    x_out, _ = multi_intervention.apply_intervention_after_layer(x, 1, key_padding_mask)
    
    # è®¡ç®—æŸå¤±
    loss = x_out.sum()
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    assert x.grad is not None, "è¾“å…¥åº”è¯¥æœ‰æ¢¯åº¦"
    assert not torch.isnan(x.grad).any(), "æ¢¯åº¦ä¸åº”è¯¥åŒ…å«NaN"
    
    print("âœ“ æ¢¯åº¦æµæµ‹è¯•é€šè¿‡")
    return True

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹æµ‹è¯•æ”¹è¿›çš„å› æœå¹²é¢„æ¡†æ¶...")
    print("=" * 50)
    
    tests = [
        test_conservative_anomaly_detector,
        test_smart_feature_decorrelation,
        test_improved_causal_gate,
        test_feature_protection,
        test_gradual_intervention,
        test_improved_ultra_light_layer,
        test_multi_level_intervention,
        test_intervention_strategies,
        test_gradient_flow,
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if test_func():
                passed += 1
        except Exception as e:
            print(f"âœ— {test_func.__name__} å¤±è´¥: {e}")
    
    print("=" * 50)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¡†æ¶é›†æˆæˆåŠŸã€‚")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤ã€‚")
    
    return passed == total

if __name__ == "__main__":
    main()