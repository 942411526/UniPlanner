#!/usr/bin/env python3
"""
æµ‹è¯•ç®€å•æœ‰æ•ˆçš„è‡ªé€‚åº”å¹²é¢„æ¡†æ¶
éªŒè¯åœ¨CRå’ŒNCRç¯å¢ƒä¸­çš„è¡¨ç°
"""

import torch
import torch.nn as nn
from simple_effective_intervention import (
    SimpleEffectiveMultiLevelCausalIntervention,
    create_simple_effective_intervention,
    create_cr_focused_intervention
)

def simulate_cr_environment(batch_size=4, seq_len=20, dim=128):
    """
    æ¨¡æ‹ŸCRç¯å¢ƒï¼šé«˜å¤æ‚åº¦ï¼ŒåŠ¨æ€äº¤äº’
    """
    # é«˜æ–¹å·®ï¼Œå¤æ‚ç‰¹å¾ï¼Œæ›´å¤šå¼‚å¸¸
    x = torch.randn(batch_size, seq_len, dim) * 3.0  # é«˜æ–¹å·®
    # æ·»åŠ æ›´å¤šå¼‚å¸¸å€¼
    x[:, :10, :] += torch.randn(batch_size, 10, dim) * 5.0
    # æ·»åŠ ä¸€äº›æç«¯å€¼
    x[:, 15:20, :] += torch.randn(batch_size, 5, dim) * 8.0
    return x

def simulate_ncr_environment(batch_size=4, seq_len=20, dim=128):
    """
    æ¨¡æ‹ŸNCRç¯å¢ƒï¼šä½å¤æ‚åº¦ï¼Œé™æ€ç¯å¢ƒ
    """
    # ä½æ–¹å·®ï¼Œç®€å•ç‰¹å¾
    x = torch.randn(batch_size, seq_len, dim) * 0.2  # ä½æ–¹å·®
    return x

def test_simple_effective_intervention():
    """
    æµ‹è¯•ç®€å•æœ‰æ•ˆçš„å¹²é¢„æ¡†æ¶
    """
    print("æµ‹è¯•ç®€å•æœ‰æ•ˆçš„è‡ªé€‚åº”å¹²é¢„æ¡†æ¶")
    print("=" * 60)
    
    # åˆ›å»ºç®€å•æœ‰æ•ˆçš„å¹²é¢„æ¡†æ¶
    intervention = create_simple_effective_intervention()
    
    # æµ‹è¯•CRç¯å¢ƒ
    print("\n1. æµ‹è¯•CRç¯å¢ƒï¼ˆé«˜æ–¹å·®ï¼Œå¤æ‚ç‰¹å¾ï¼‰:")
    cr_x = simulate_cr_environment()
    intervention.train()
    
    cr_metrics = {}
    for layer_idx in range(4):
        cr_x, metrics = intervention.apply_intervention_after_layer(cr_x, layer_idx)
        if metrics:
            cr_metrics[f'layer_{layer_idx}'] = metrics
            print(f"  ç¬¬{layer_idx}å±‚: ç¯å¢ƒ={metrics.get('env_type', 'Unknown')}, "
                  f"æ–¹å·®={metrics.get('variance', 0):.3f}, "
                  f"è‡ªé€‚åº”æ¦‚ç‡={metrics.get('adaptive_prob', 0):.3f}, "
                  f"é˜ˆå€¼={metrics.get('threshold_used', 0):.3f}, "
                  f"å¼‚å¸¸æ¯”ä¾‹={metrics.get('anomaly_ratio', 0):.3f}")
    
    # æµ‹è¯•NCRç¯å¢ƒ
    print("\n2. æµ‹è¯•NCRç¯å¢ƒï¼ˆä½æ–¹å·®ï¼Œç®€å•ç‰¹å¾ï¼‰:")
    ncr_x = simulate_ncr_environment()
    
    ncr_metrics = {}
    for layer_idx in range(4):
        ncr_x, metrics = intervention.apply_intervention_after_layer(ncr_x, layer_idx)
        if metrics:
            ncr_metrics[f'layer_{layer_idx}'] = metrics
            print(f"  ç¬¬{layer_idx}å±‚: ç¯å¢ƒ={metrics.get('env_type', 'Unknown')}, "
                  f"æ–¹å·®={metrics.get('variance', 0):.3f}, "
                  f"è‡ªé€‚åº”æ¦‚ç‡={metrics.get('adaptive_prob', 0):.3f}, "
                  f"é˜ˆå€¼={metrics.get('threshold_used', 0):.3f}, "
                  f"å¼‚å¸¸æ¯”ä¾‹={metrics.get('anomaly_ratio', 0):.3f}")
    
    # åˆ†æç»“æœ
    print("\n3. è¯¦ç»†åˆ†æ:")
    
    # è®¡ç®—å¹³å‡æ–¹å·®
    cr_avg_variance = sum(m.get('variance', 0) for m in cr_metrics.values()) / len(cr_metrics)
    ncr_avg_variance = sum(m.get('variance', 0) for m in ncr_metrics.values()) / len(ncr_metrics)
    
    print(f"  CRç¯å¢ƒå¹³å‡æ–¹å·®: {cr_avg_variance:.3f}")
    print(f"  NCRç¯å¢ƒå¹³å‡æ–¹å·®: {ncr_avg_variance:.3f}")
    
    # è®¡ç®—å¹³å‡å¹²é¢„æ¦‚ç‡
    cr_avg_prob = sum(m.get('adaptive_prob', 0) for m in cr_metrics.values()) / len(cr_metrics)
    ncr_avg_prob = sum(m.get('adaptive_prob', 0) for m in ncr_metrics.values()) / len(ncr_metrics)
    
    print(f"  CRç¯å¢ƒå¹³å‡å¹²é¢„æ¦‚ç‡: {cr_avg_prob:.3f}")
    print(f"  NCRç¯å¢ƒå¹³å‡å¹²é¢„æ¦‚ç‡: {ncr_avg_prob:.3f}")
    
    # è®¡ç®—å¹³å‡é˜ˆå€¼
    cr_avg_threshold = sum(m.get('threshold_used', 0) for m in cr_metrics.values()) / len(cr_metrics)
    ncr_avg_threshold = sum(m.get('threshold_used', 0) for m in ncr_metrics.values()) / len(ncr_metrics)
    
    print(f"  CRç¯å¢ƒå¹³å‡é˜ˆå€¼: {cr_avg_threshold:.3f}")
    print(f"  NCRç¯å¢ƒå¹³å‡é˜ˆå€¼: {ncr_avg_threshold:.3f}")
    
    # éªŒè¯è‡ªé€‚åº”è¡Œä¸º
    print("\n4. è‡ªé€‚åº”è¡Œä¸ºéªŒè¯:")
    
    if cr_avg_prob > ncr_avg_prob:
        print("  âœ… å¹²é¢„æ¦‚ç‡è‡ªé€‚åº”æ­£ç¡®ï¼šCRç¯å¢ƒä½¿ç”¨æ›´é«˜çš„å¹²é¢„æ¦‚ç‡")
    else:
        print("  âŒ å¹²é¢„æ¦‚ç‡è‡ªé€‚åº”å¼‚å¸¸ï¼šCRç¯å¢ƒå¹²é¢„æ¦‚ç‡è¿‡ä½")
    
    if cr_avg_threshold < ncr_avg_threshold:
        print("  âœ… é˜ˆå€¼è‡ªé€‚åº”æ­£ç¡®ï¼šCRç¯å¢ƒä½¿ç”¨æ›´æ•æ„Ÿçš„é˜ˆå€¼")
    else:
        print("  âŒ é˜ˆå€¼è‡ªé€‚åº”å¼‚å¸¸ï¼šCRç¯å¢ƒé˜ˆå€¼ä¸å¤Ÿæ•æ„Ÿ")
    
    if cr_avg_variance > ncr_avg_variance:
        print("  âœ… æ–¹å·®æ£€æµ‹æ­£ç¡®ï¼šCRç¯å¢ƒè¢«è¯†åˆ«ä¸ºé«˜æ–¹å·®ç¯å¢ƒ")
    else:
        print("  âŒ æ–¹å·®æ£€æµ‹å¼‚å¸¸ï¼šCRç¯å¢ƒæ–¹å·®æ£€æµ‹ä¸å‡†ç¡®")
    
    return cr_metrics, ncr_metrics

def test_cr_focused_version():
    """
    æµ‹è¯•CRä¼˜åŒ–ç‰ˆæœ¬
    """
    print("\n5. æµ‹è¯•CRä¼˜åŒ–ç‰ˆæœ¬:")
    
    # åˆ›å»ºCRä¼˜åŒ–ç‰ˆæœ¬
    cr_intervention = create_cr_focused_intervention()
    
    # æµ‹è¯•CRç¯å¢ƒ
    cr_x = simulate_cr_environment()
    cr_intervention.train()
    
    cr_metrics = {}
    for layer_idx in range(4):
        cr_x, metrics = cr_intervention.apply_intervention_after_layer(cr_x, layer_idx)
        if metrics:
            cr_metrics[f'layer_{layer_idx}'] = metrics
    
    # è®¡ç®—CRä¼˜åŒ–ç‰ˆæœ¬çš„æ•ˆæœ
    cr_avg_prob = sum(m.get('adaptive_prob', 0) for m in cr_metrics.values()) / len(cr_metrics)
    cr_avg_threshold = sum(m.get('threshold_used', 0) for m in cr_metrics.values()) / len(cr_metrics)
    cr_avg_variance = sum(m.get('variance', 0) for m in cr_metrics.values()) / len(cr_metrics)
    
    print(f"  CRä¼˜åŒ–ç‰ˆæœ¬ - å¹³å‡å¹²é¢„æ¦‚ç‡: {cr_avg_prob:.3f}")
    print(f"  CRä¼˜åŒ–ç‰ˆæœ¬ - å¹³å‡é˜ˆå€¼: {cr_avg_threshold:.3f}")
    print(f"  CRä¼˜åŒ–ç‰ˆæœ¬ - å¹³å‡æ–¹å·®: {cr_avg_variance:.3f}")
    
    return cr_metrics

def test_gradient_flow():
    """
    æµ‹è¯•æ¢¯åº¦æµ
    """
    print("\n6. æµ‹è¯•æ¢¯åº¦æµ:")
    
    intervention = create_simple_effective_intervention()
    x = torch.randn(2, 10, 128, requires_grad=True)
    
    intervention.train()
    x_out, _ = intervention.apply_intervention_after_layer(x, 1)
    
    loss = x_out.sum()
    loss.backward()
    
    print(f"  è¾“å…¥æ¢¯åº¦å½¢çŠ¶: {x.grad.shape}")
    print(f"  æ¢¯åº¦èŒƒæ•°: {x.grad.norm().item():.6f}")
    print("  âœ… æ¢¯åº¦æµæ­£å¸¸")

def test_parameter_learning():
    """
    æµ‹è¯•å‚æ•°å­¦ä¹ 
    """
    print("\n7. æµ‹è¯•å‚æ•°å­¦ä¹ :")
    
    intervention = create_simple_effective_intervention()
    
    # æ£€æŸ¥å¯å­¦ä¹ å‚æ•°
    learnable_params = []
    for name, param in intervention.named_parameters():
        if param.requires_grad:
            learnable_params.append((name, param.shape))
    
    print(f"  å¯å­¦ä¹ å‚æ•°æ•°é‡: {len(learnable_params)}")
    for name, shape in learnable_params:
        print(f"    {name}: {shape}")
    
    print("  âœ… å‚æ•°å­¦ä¹ æ­£å¸¸")

def main():
    """
    ä¸»æµ‹è¯•å‡½æ•°
    """
    print("å¼€å§‹æµ‹è¯•ç®€å•æœ‰æ•ˆçš„è‡ªé€‚åº”å¹²é¢„æ¡†æ¶...")
    
    try:
        # æµ‹è¯•ç®€å•æœ‰æ•ˆçš„å¹²é¢„æ¡†æ¶
        cr_metrics, ncr_metrics = test_simple_effective_intervention()
        
        # æµ‹è¯•CRä¼˜åŒ–ç‰ˆæœ¬
        cr_opt_metrics = test_cr_focused_version()
        
        # æµ‹è¯•æ¢¯åº¦æµ
        test_gradient_flow()
        
        # æµ‹è¯•å‚æ•°å­¦ä¹ 
        test_parameter_learning()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("\nç®€å•æœ‰æ•ˆæ”¹è¿›æ€»ç»“:")
        print("1. åŸºäºæ–¹å·®çš„å¤æ‚åº¦æ£€æµ‹ - ç®€å•ä½†æœ‰æ•ˆ")
        print("2. è‡ªé€‚åº”å¹²é¢„æ¦‚ç‡ - é«˜æ–¹å·®ç¯å¢ƒä½¿ç”¨æ›´é«˜æ¦‚ç‡")
        print("3. è‡ªé€‚åº”é˜ˆå€¼ - é«˜æ–¹å·®ç¯å¢ƒä½¿ç”¨æ›´æ•æ„Ÿé˜ˆå€¼")
        print("4. è‡ªé€‚åº”å™ªå£°å¼ºåº¦ - æ ¹æ®ç¯å¢ƒç±»å‹è°ƒæ•´å™ªå£°")
        print("5. ç®€å•å®ç° - æ˜“äºç†è§£å’Œè°ƒè¯•")
        
        print("\né¢„æœŸæ•ˆæœ:")
        print("- CRç¯å¢ƒï¼ˆé«˜æ–¹å·®ï¼‰ï¼šæ›´å¼ºå¹²é¢„ï¼Œæ›´æ•æ„Ÿé˜ˆå€¼ï¼Œæ›´é«˜æ¦‚ç‡")
        print("- NCRç¯å¢ƒï¼ˆä½æ–¹å·®ï¼‰ï¼šæ¸©å’Œå¹²é¢„ï¼Œä¿å®ˆé˜ˆå€¼ï¼Œè¾ƒä½æ¦‚ç‡")
        print("- åŸºäºç‰¹å¾æ–¹å·®çš„ç®€å•ä½†æœ‰æ•ˆçš„ç¯å¢ƒè¯†åˆ«")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()